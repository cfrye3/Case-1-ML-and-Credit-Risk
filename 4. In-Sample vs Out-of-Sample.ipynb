{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.255010\n",
      "         Iterations 7\n",
      "\n",
      "In-Sample vs Out-of-Sample Performance:\n",
      "Model\t\tTrain Accuracy\tTest Accuracy\n",
      "Predict all good\t0.9177\t0.9190\n",
      "Logistic Regression (Logit)\t0.9178\t0.9191\n",
      "Decision Tree\t\t1.0000\t0.8489\n",
      "Neural Network\t\t0.9165\t0.9176\n",
      "\n",
      "Logistic Regression (Logit) Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:               137968\n",
      "Model:                          Logit   Df Residuals:                   137954\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 26 May 2025   Pseudo R-squ.:                  0.1032\n",
      "Time:                        16:24:14   Log-Likelihood:                -35183.\n",
      "converged:                       True   LL-Null:                       -39232.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.0474      0.052     -0.906      0.365      -0.150       0.055\n",
      "amt_income_total    2.535e-08    2.6e-08      0.977      0.329   -2.55e-08    7.62e-08\n",
      "credit_score_mean     -5.5339      0.077    -72.311      0.000      -5.684      -5.384\n",
      "amt_credit          2.241e-08   2.83e-08      0.792      0.428   -3.31e-08    7.79e-08\n",
      "days_employed      -8.344e-05   5.73e-06    -14.573      0.000   -9.47e-05   -7.22e-05\n",
      "document_count         0.2563      0.030      8.416      0.000       0.197       0.316\n",
      "credit_score_stdev     0.5461      0.100      5.458      0.000       0.350       0.742\n",
      "age_range              0.0551      0.012      4.697      0.000       0.032       0.078\n",
      "educated              -0.4283      0.026    -16.600      0.000      -0.479      -0.378\n",
      "children               0.0406      0.022      1.824      0.068      -0.003       0.084\n",
      "married               -0.0362      0.027     -1.354      0.176      -0.089       0.016\n",
      "flag_own_car          -0.2550      0.023    -11.246      0.000      -0.299      -0.211\n",
      "flag_own_realty        0.0788      0.022      3.570      0.000       0.036       0.122\n",
      "code_gender            0.1990      0.022      9.107      0.000       0.156       0.242\n",
      "======================================================================================\n",
      "Depth (number of levels) of the Decision Tree: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Replace this with the path to your CSV file\n",
    "file_path = '/Users/christopherfrye/Library/Mobile Documents/com~apple~CloudDocs/NYU Stern/2025_Summer Term/AI in Finance/home_credit_cleaned.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all categorical variables are encoded\n",
    "categorical_columns = ['code_gender', 'flag_own_car', 'flag_own_realty', 'age_range', 'educated', 'children', 'married']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define your features and target\n",
    "X = df[['amt_income_total', 'credit_score_mean', 'amt_credit', 'days_employed', \n",
    "        'document_count', 'credit_score_stdev', 'age_range', 'educated', \n",
    "        'children', 'married', 'flag_own_car', 'flag_own_realty','code_gender']]\n",
    "y = df['default']\n",
    "\n",
    "# Add a constant to the model (for the intercept term in statsmodels)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# 1. Predict all good (baseline model)\n",
    "# -------------------------\n",
    "# The \"predict all good\" model predicts \"0\" (non-default) for all instances\n",
    "y_pred_all_good_train = np.zeros_like(y_train)\n",
    "y_pred_all_good_test = np.zeros_like(y_test)\n",
    "\n",
    "accuracy_train_all_good = accuracy_score(y_train, y_pred_all_good_train)\n",
    "accuracy_test_all_good = accuracy_score(y_test, y_pred_all_good_test)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Logistic Regression (Logit)\n",
    "# -------------------------\n",
    "# Initialize and train the logistic regression (Logit) model using statsmodels\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "logit_model_fitted = logit_model.fit()\n",
    "\n",
    "# Predict on train and test data\n",
    "y_pred_logit_train = logit_model_fitted.predict(X_train)\n",
    "y_pred_logit_test = logit_model_fitted.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary outcomes (1 for default, 0 for repaid) using a 0.5 threshold\n",
    "y_pred_logit_train_bin = np.where(y_pred_logit_train > 0.5, 1, 0)\n",
    "y_pred_logit_test_bin = np.where(y_pred_logit_test > 0.5, 1, 0)\n",
    "\n",
    "accuracy_train_logit = accuracy_score(y_train, y_pred_logit_train_bin)\n",
    "accuracy_test_logit = accuracy_score(y_test, y_pred_logit_test_bin)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Decision Tree\n",
    "# -------------------------\n",
    "# Initialize and train the decision tree classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "y_pred_dt_train = dt_model.predict(X_train)\n",
    "y_pred_dt_test = dt_model.predict(X_test)\n",
    "\n",
    "accuracy_train_dt = accuracy_score(y_train, y_pred_dt_train)\n",
    "accuracy_test_dt = accuracy_score(y_test, y_pred_dt_test)\n",
    "\n",
    "# ------------------------\n",
    "# 4. Neural Network (MLP)\n",
    "# ------------------------\n",
    "# Initialize and train the MLP classifier (neural network)\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "y_pred_mlp_train = mlp_model.predict(X_train)\n",
    "y_pred_mlp_test = mlp_model.predict(X_test)\n",
    "\n",
    "accuracy_train_mlp = accuracy_score(y_train, y_pred_mlp_train)\n",
    "accuracy_test_mlp = accuracy_score(y_test, y_pred_mlp_test)\n",
    "\n",
    "# ------------------------\n",
    "# Output and Evaluation\n",
    "# ------------------------\n",
    "\n",
    "# Print the results in the requested table format\n",
    "print(\"\\nIn-Sample vs Out-of-Sample Performance:\")\n",
    "print(f\"Model\\t\\tTrain Accuracy\\tTest Accuracy\")\n",
    "print(f\"Predict all good\\t{accuracy_train_all_good:.4f}\\t{accuracy_test_all_good:.4f}\")\n",
    "print(f\"Logistic Regression (Logit)\\t{accuracy_train_logit:.4f}\\t{accuracy_test_logit:.4f}\")\n",
    "print(f\"Decision Tree\\t\\t{accuracy_train_dt:.4f}\\t{accuracy_test_dt:.4f}\")\n",
    "print(f\"Neural Network\\t\\t{accuracy_train_mlp:.4f}\\t{accuracy_test_mlp:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Optional: Display the Logit summary for the Logistic Regression model\n",
    "print(\"\\nLogistic Regression (Logit) Model Summary:\")\n",
    "print(logit_model_fitted.summary())\n",
    "\n",
    "# Get the depth of the tree (number of levels)\n",
    "tree_depth = dt_model.tree_.max_depth\n",
    "\n",
    "print(f\"Depth (number of levels) of the Decision Tree: {tree_depth}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
