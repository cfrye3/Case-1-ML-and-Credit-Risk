{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31698     0]\n",
      " [ 2794     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     31698\n",
      "           1       0.00      0.00      0.00      2794\n",
      "\n",
      "    accuracy                           0.92     34492\n",
      "   macro avg       0.46      0.50      0.48     34492\n",
      "weighted avg       0.84      0.92      0.88     34492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Statistics (from statsmodels):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                default   R-squared:                       0.059\n",
      "Model:                            OLS   Adj. R-squared:                  0.059\n",
      "Method:                 Least Squares   F-statistic:                     727.3\n",
      "Date:                Mon, 26 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:24:36   Log-Likelihood:                -13334.\n",
      "No. Observations:              137968   AIC:                         2.669e+04\n",
      "Df Residuals:                  137955   BIC:                         2.682e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.3192      0.004     76.216      0.000       0.311       0.327\n",
      "amt_income_total    6.775e-09   2.16e-09      3.135      0.002    2.54e-09     1.1e-08\n",
      "credit_score_mean     -0.4545      0.006    -78.951      0.000      -0.466      -0.443\n",
      "amt_credit          2.235e-09   1.85e-09      1.210      0.226   -1.38e-09    5.85e-09\n",
      "days_employed      -4.469e-06   3.27e-07    -13.665      0.000   -5.11e-06   -3.83e-06\n",
      "document_count         0.0162      0.002      7.886      0.000       0.012       0.020\n",
      "credit_score_stdev    -0.0489      0.008     -6.351      0.000      -0.064      -0.034\n",
      "age_range              0.0048      0.001      5.676      0.000       0.003       0.007\n",
      "educated              -0.0257      0.002    -15.927      0.000      -0.029      -0.023\n",
      "children               0.0011      0.002      0.669      0.503      -0.002       0.004\n",
      "married               -0.0054      0.002     -2.728      0.006      -0.009      -0.002\n",
      "flag_own_car          -0.0137      0.001     -9.255      0.000      -0.017      -0.011\n",
      "flag_own_realty        0.0054      0.002      3.460      0.001       0.002       0.008\n",
      "==============================================================================\n",
      "Omnibus:                    75728.517   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           415956.940\n",
      "Skew:                           2.774   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.448   Cond. No.                     9.19e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.19e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Replace this with the path to your CSV file\n",
    "file_path = '/Users/christopherfrye/Library/Mobile Documents/com~apple~CloudDocs/NYU Stern/2025_Summer Term/AI in Finance/home_credit_cleaned.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all categorical variables are encoded\n",
    "categorical_columns = ['code_gender', 'flag_own_car', 'flag_own_realty', 'age_range', 'educated', 'children', 'married']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define your features and target\n",
    "X = df[['amt_income_total', 'credit_score_mean', 'amt_credit', 'days_employed', \n",
    "        'document_count', 'credit_score_stdev', 'age_range', 'educated', \n",
    "        'children', 'married', 'flag_own_car', 'flag_own_realty']]\n",
    "y = df['default']\n",
    "\n",
    "# Add a constant to the model (for the intercept term in statsmodels)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Linear Regression model from sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions (probabilities)\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary outcomes (1 for default, 0 for repaid) using a 0.5 threshold\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Evaluate the performance using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# Additional evaluation: confusion matrix and classification report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Now, we will fit the same model using statsmodels to get regression statistics\n",
    "ols_model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Output the OLS regression summary statistics (RÂ², p-values, t-statistics, etc.)\n",
    "print(\"\\nLinear Regression Statistics (from statsmodels):\")\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Summary (After Backward Elimination):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                default   R-squared:                       0.059\n",
      "Model:                            OLS   Adj. R-squared:                  0.059\n",
      "Method:                 Least Squares   F-statistic:                     872.6\n",
      "Date:                Mon, 26 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:27:44   Log-Likelihood:                -13334.\n",
      "No. Observations:              137968   AIC:                         2.669e+04\n",
      "Df Residuals:                  137957   BIC:                         2.680e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.3195      0.004     76.763      0.000       0.311       0.328\n",
      "amt_income_total    7.025e-09   2.15e-09      3.265      0.001    2.81e-09    1.12e-08\n",
      "credit_score_mean     -0.4537      0.006    -79.278      0.000      -0.465      -0.442\n",
      "days_employed      -4.462e-06   3.27e-07    -13.646      0.000    -5.1e-06   -3.82e-06\n",
      "document_count         0.0167      0.002      8.355      0.000       0.013       0.021\n",
      "credit_score_stdev    -0.0489      0.008     -6.343      0.000      -0.064      -0.034\n",
      "age_range              0.0048      0.001      5.857      0.000       0.003       0.006\n",
      "educated              -0.0255      0.002    -15.899      0.000      -0.029      -0.022\n",
      "married               -0.0048      0.002     -2.546      0.011      -0.009      -0.001\n",
      "flag_own_car          -0.0136      0.001     -9.175      0.000      -0.016      -0.011\n",
      "flag_own_realty        0.0054      0.002      3.454      0.001       0.002       0.008\n",
      "==============================================================================\n",
      "Omnibus:                    75729.802   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           415969.975\n",
      "Skew:                           2.774   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.448   Cond. No.                     4.47e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.47e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Optimal Model Accuracy: 0.9190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31698     0]\n",
      " [ 2794     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     31698\n",
      "           1       0.00      0.00      0.00      2794\n",
      "\n",
      "    accuracy                           0.92     34492\n",
      "   macro avg       0.46      0.50      0.48     34492\n",
      "weighted avg       0.84      0.92      0.88     34492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/christopherfrye/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Backward Elimination on Linear Regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Replace this with the path to your CSV file\n",
    "file_path = '/Users/christopherfrye/Library/Mobile Documents/com~apple~CloudDocs/NYU Stern/2025_Summer Term/AI in Finance/home_credit_cleaned.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all categorical variables are encoded\n",
    "categorical_columns = ['code_gender', 'flag_own_car', 'flag_own_realty', 'age_range', 'educated', 'children', 'married']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define your features and target\n",
    "X = df[['amt_income_total', 'credit_score_mean', 'amt_credit', 'days_employed', \n",
    "        'document_count', 'credit_score_stdev', 'age_range', 'educated', \n",
    "        'children', 'married', 'flag_own_car', 'flag_own_realty']]\n",
    "y = df['default']\n",
    "\n",
    "# Add a constant to the model (for the intercept term in statsmodels)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Backward Elimination Process\n",
    "def backward_elimination(X_train, y_train, significance_level=0.05):\n",
    "    initial_features = X_train.columns\n",
    "    while True:\n",
    "        # Fit the model with the current features\n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "        \n",
    "        # Get p-values for the features\n",
    "        p_values = model.pvalues[1:]  # Exclude the constant term\n",
    "        \n",
    "        # Find the feature with the highest p-value\n",
    "        max_p_value = p_values.max()\n",
    "        feature_with_max_p_value = p_values.idxmax()\n",
    "        \n",
    "        # If the max p-value is greater than the significance level, remove the feature\n",
    "        if max_p_value > significance_level:\n",
    "            X_train = X_train.drop(columns=[feature_with_max_p_value])\n",
    "        else:\n",
    "            break  # If no feature has p-value greater than the threshold, stop\n",
    "    \n",
    "    return X_train, model\n",
    "\n",
    "# Perform backward elimination to get the optimal set of features\n",
    "X_train_optimal, optimal_model = backward_elimination(X_train, y_train)\n",
    "\n",
    "# Output the final model summary with optimal features\n",
    "print(\"\\nFinal Model Summary (After Backward Elimination):\")\n",
    "print(optimal_model.summary())\n",
    "\n",
    "# Make sure to add the constant to the test set as well (so it has the same shape as the training set)\n",
    "X_test_optimal = sm.add_constant(X_test[X_train_optimal.columns])\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "y_pred_optimal = optimal_model.predict(X_test_optimal)\n",
    "\n",
    "# Convert the probabilities to binary outcomes (1 for default, 0 for repaid) using a 0.5 threshold\n",
    "y_pred_binary = np.where(y_pred_optimal > 0.5, 1, 0)\n",
    "\n",
    "# Performance evaluation: accuracy, confusion matrix, and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'\\nOptimal Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_binary))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
